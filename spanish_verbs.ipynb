{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spanish Verb Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "- Extract Verbs from webpage\n",
    "- Create a List that combines all verbs from differents urls\n",
    "- reshape list to create arrays\n",
    "- Store data in DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.common import exceptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Verbs from webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraper(url):\n",
    "    # access to web page using requests lib\n",
    "\n",
    "    service = Service(ChromeDriverManager().install()) \n",
    "\n",
    "    # we will use webdriver from selenuim to get the content from the web \n",
    "    driver = webdriver.Chrome(service=service) \n",
    "    response = driver.get(url)\n",
    "    \n",
    "    return driver.page_source\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2000 verbos populares en español en conjugador reverso ( dale clic a los vínculos)  | Verbling'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create soup to put in our html content\n",
    "url = 'https://www.verbling.com/fr/discussion/2000-verbos-populares-en-espanol-en-conjugador-reverso-dale-'\n",
    "soup = BeautifulSoup(scraper(url), 'html.parser')\n",
    "title = soup.title.text.strip()\n",
    "title "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://conjugador.reverso.net/index-espanol-1-250.html\n",
      "https://conjugador.reverso.net/index-espanol-251-500.html\n",
      "https://conjugador.reverso.net/index-espanol-501-750.html\n",
      "https://conjugador.reverso.net/index-espanol-751-1000.html\n",
      "https://conjugador.reverso.net/index-espanol-1001-1250.html\n",
      "https://conjugador.reverso.net/index-espanol-1251-1500.html\n",
      "https://conjugador.reverso.net/index-espanol-1501-1750.html\n",
      "https://conjugador.reverso.net/index-espanol-1751-2000.html\n"
     ]
    }
   ],
   "source": [
    "# Obtain all urls that contain our verbs and store them in a list\n",
    "a = soup.find_all('a', attrs={'rel':'nofollow noopener noreferrer'})\n",
    "urls = []\n",
    "for url in a :\n",
    "    print(url.get('href'))\n",
    "    urls.append(url.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbos más usados en Español desde ser hasta cortar | Conjugador Reverso\n",
      "Verbos más usados en Español desde vigilar hasta reafirmar | Conjugador Reverso\n",
      "Verbos más usados en Español desde dañar hasta liderar | Conjugador Reverso\n",
      "Verbos más usados en Español desde rehabilitar hasta acuñar | Conjugador Reverso\n",
      "Verbos más usados en Español desde transportar hasta contabilizar | Conjugador Reverso\n",
      "Verbos más usados en Español desde saquear hasta aludir | Conjugador Reverso\n",
      "Verbos más usados en Español desde embalar hasta atemorizar | Conjugador Reverso\n",
      "Verbos más usados en Español desde atrasar hasta precautelar | Conjugador Reverso\n"
     ]
    }
   ],
   "source": [
    "for url in urls:\n",
    "    soup = BeautifulSoup(scraper(url), 'html.parser')\n",
    "    title = soup.title\n",
    "    if title is not None :\n",
    "        print(title.text.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now after we succeffuly collect our all contenaire that store our verb we will insert all verbs in a single list\n",
    "# We trait the first contenair after we loop all together\n",
    "soup_2 = BeautifulSoup(scraper('https://conjugador.reverso.net/index-espanol-1-250.html'), 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a List that combines all verbs from differents urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs = soup_2.find('div', attrs = {'class': 'index-content'})\n",
    "all_verbs = []\n",
    "for verb in verbs:\n",
    "    v  = verb.text.strip()\n",
    "    if verb.text != '\\n':\n",
    "        all_verbs.append(v.split('\\n\\n\\n'))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list to collect all verbs\n",
    "all_verbs = []\n",
    "\n",
    "for url in urls:\n",
    "    \n",
    "    # iterate access urls\n",
    "    soup_2 = BeautifulSoup(scraper(url), 'html.parser')\n",
    "\n",
    "    verbs = soup_2.find('div', attrs = {'class': 'index-content'})\n",
    "    \n",
    "    for verb in verbs:\n",
    "\n",
    "        v  = verb.text.strip()\n",
    "\n",
    "        if verb.text != '\\n':\n",
    "            \n",
    "            all_verbs.append(v.split('\\n\\n\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show how much nested list we have\n",
    "len(all_verbs) # if there are 8 so all contenaires are included"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reshape list to create arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove multiple dimensions from list\n",
    "verbs = []\n",
    "for nestedlist in all_verbs:\n",
    "    for vrb in nestedlist:\n",
    "        verbs.append(vrb)\n",
    "verbs.append(' ')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list to numpy array\n",
    "arr = np.array(verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['ser', 'ver', 'decir', ..., 'seguir', 'promover', 'mantener'],\n",
       "       ['dejar', 'evitar', 'dar', ..., 'llevar', 'aplicar',\n",
       "        'desarrollar'],\n",
       "       ['facilitar', 'apoyar', 'determinar', ..., 'esperar', 'salir',\n",
       "        'matar'],\n",
       "       ...,\n",
       "       ['desatascar', 'fruncir', 'corroer', ..., 'vivificar', 'cebar',\n",
       "        'enaltecer'],\n",
       "       ['extraviar', 'hartar', 'hilvanar', ..., 'aparear', 'espabilar',\n",
       "        'graznar'],\n",
       "       ['readquirir', 'zarandear', 'capitanear', ..., 'fustigar',\n",
       "        'precautelar', ' ']], dtype='<U17')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape array to 100 rows and 20 columns\n",
    "array = arr.reshape(100, 20)\n",
    "array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store data in DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert array to DataFrame\n",
    "df = pd.DataFrame(array )\n",
    "\n",
    "# Rename rows and columns\n",
    "df.columns =  ['Verbo  ' + str(i) for i in range(1, 21)]\n",
    "df.index =  ['Dia ' + str(i) for i in range(1, 101)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to csv\n",
    "import_csv = df.to_csv('2000_verbos.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
